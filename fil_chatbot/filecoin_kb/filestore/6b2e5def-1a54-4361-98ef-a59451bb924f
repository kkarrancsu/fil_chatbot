{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "Suppose we have two probability distributions $\\mu_\\text{target}$ a target probability distribution that we would like to sample from, and a reference probability distribution that is easy to sample from (a multi-variate Gaussian, for example). In the context of  NFs, it is typically the case that sampling from $\\mu_\\text{target}$ directly is unfeasible. This could happen e.g. because such a probability distribution is not known, it is high-dimensional, etc. Despite this difficulty, it is also often the case that a set of samples from such a distribution is available apriori.  The idea behind  normalizing flows is to use deep neural networks to approximate an invertible map $T$ such that $T_\\sharp \\mu_\\text{target}=\\mu_\\text{ref}$, i.e., that the pushforward  of $\\mu_\\text{target}$ through $T$ is the reference measure $\\mu_\\text{ref}$.  Notice that, in practice,  the measure $\\mu_\\text{target}$ is approximated by the empirical measure obtained from its samples. Once such an invertible transformation $T$ has", "metadata": {}}}