{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "$$\n\\begin{align*}\n   & \\sum_{t=1}^n \\bigg( (1-\\beta)\\cdot R_t + \\beta (R_t - P) \\bigg) > \\tau \\sum_{t=1}^n R_t  \\Longleftrightarrow\\\\\n   & \\Longleftrightarrow \\sum_{t=1}^n \\bigg(R_t - \\beta \\cdot P \\bigg) > \\tau \\sum_{t=1}^n R_t  \\Longleftrightarrow\\\\\n   & \\Longleftrightarrow \\sum_{t=1}^n R_t - \\beta \\cdot n \\cdot P > \\tau \\sum_{t=1}^n R_t  \\Longleftrightarrow\\\\\n   & \\Longleftrightarrow P < \\frac{1-\\tau}{\\beta} \\cdot \\frac{\\sum_{t=1}^n R_t}{n}\\\\\n\\end{align*}\n$$\n\nIn other words, the penalty needs to be smaller that $(1-\\tau) / \\beta$ times the average reward of the node (before penalties).\n\n#### Bounds estimation\n\nIn this section, we plot the *penalty adjustment* derived above, assuming a range of values for the true positive rate $\\alpha$, the false positive rate $\\beta$ and the minimum reward ratio $\\tau$. Note that the *penalty adjustment* is a fixed number to be multiplied by each node's average reward (excluding penalties).\n\nThe next plots show the values obtained:", "metadata": {}}}